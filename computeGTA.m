function computeGTA(foldname,network)
%{
function:
computes global and nodal graph theory metrics
append them to data table for each participant
also outputs raw results for the nodal measures at different thresholds

input:
-foldname: e.g., 'FCmatrices' -> string for folder name in the same path as
current function, in which there are .mat files containing structs
corresponding to connectivity matrices. This folder can be produced by the
function "ROItoFC"
-network: specification of what nodes should be in the network analysed;
this can be e.g., "S400T54" (for the 454 ROI whole-brain analysis), or
DNCN400 for results from just the DMN-FPCN nodes



output:
-LegacyGlobalGTA_XX.csv: n_subject x n_measures matrix
    -Contents listed:
        -subject id
        -modularity score (both via consensus clustering, and via finding the maximum modularity score in all )
        -assortativity: from all positive weigths, from only negative weights, and using absolute value of connections
        -Global metrics, i.e., global efficiency
-LegacyNodalGTA_XX.csv: (n_subject x n_nodes) x n_measures matrix
    -Contents listed:
        -subject id
        -region names: name of each node (from the file loaded/generated by ROItoFC
       	-Community Affiliation Vector
        -Participation coefficient for diversity of connections, from only positive or only negative weights
        -Centrality: Degree and EigenvectorCentrality, together with Strength

IMPORTANT: requires Brain Connectivity Toolbox functions

detailed notes on methodology to be found in main github page


%}
    %% get FC matrices
    nos = what(foldname);
    fnames = nos.mat;
    %extract subject file number 
    snum = extractBetween(fnames,'Subject','.mat');
    addpath(foldname)
    
    iteration = 0;
    begin = 1;
    %store raw data at each threshold
    raw_glob = cell(length(snum)-begin + 1,1);
    raw_node = cell(length(snum)-begin + 1,1);
    for subj = begin:length(snum)
        iteration = iteration + 1;
        %% perform exclusion
        %participants were excluded due to missing ROIs in their scan
        exclu = [4,6,8,10,12,18,28,29,30,37,38,63,64,66,69];
        if any(exclu == subj)
            continue
        end    

        load(replace('FC_SubjectXX.mat','XX',snum{subj}),'fc')
        
        
        %% get the relevant regions
        %note: also removes the '7networks' from names
        %A: the matrix in question
        if strcmp(network,'S100')
            A = fc.S100.Z;
            regnames = myrename(fc.S100.names(:,2));
        elseif strcmp(network,'S400')
            A = fc.S400.Z;
            regnames = myrename(fc.S400.names(:,2));        
        elseif strcmp(network,'DNCN100')
            A = fc.DNCN100.Z;
            regnames = myrename(fc.DNCN100.names(:,2));
        elseif strcmp(network,'DNCN400')
            A = fc.DNCN400.Z;
            regnames = myrename(fc.DNCN400.names(:,2));        
        elseif strcmp(network,'S400T54')
            A = fc.S400T54.Z;
            regnames = [myrename(fc.S400T54.names(1:400,2));fc.S400T54.names(401:end,1)];
        end    
        %set self-connection to zero
        A = selflink(A);
        
        
        %% modularity
        % Iterative community finetuning (Sun et al., 2009?)
        n  = size(A,1);%get number of nodes
        gamma = 1;%default
        Commun_affil_ini  = 1:n;% initialise community affiliations (random, each a module)
        Q0 = -1;
        Q1 = 0;% initialize modularity values
        while Q1-Q0>1e-5 % while modularity increases
            Q0 = Q1;%update to previous iteration
            [Commun_affil_ini, Q1] = community_louvain(A, gamma, Commun_affil_ini,'negative_asym');
            %use the previous step's community structure
        end

        %% deal with non-deterministic nature
        reps = 1000;%repeat optimisation for n times
        Commun_affil_rep = nan(n,reps);
        Q1_rep = nan(reps,1);
        Q0_rep = nan(reps,1);
        for it = 1:reps
            Commun_affil_rep(:,it) = 1:n;
            Q0_rep(it) = -1;
            Q1_rep(it) = 0;
            while Q1_rep(it)-Q0_rep(it) >1e-5 % while modularity increases
                Q0_rep(it) = Q1_rep(it);%update to previous iteration
                [Commun_affil_rep(:,it), Q1_rep(it)] = community_louvain(A, gamma, Commun_affil_rep(:,it),'negative_asym');
            end
        end
                      
        %produce agreement matrix
        Agree = agreement_weighted(Commun_affil_rep,Q1_rep);

        %find consensus partition
        tau_thresh = 0.4;
        consensus_reps = reps;%by the book, use same value as previous
        Commun_affil = consensus_und(Agree,tau_thresh,consensus_reps);%Lancichinetti 2012
        %retrieve the Q1 for this final CAV
        Q_consensus = mymodularity(A,Commun_affil,gamma);
        
        %also find the max
        [Q_max,biggestQ] = max(Q1_rep);
        CAV_max = Commun_affil_rep(:,biggestQ);

        
        %% participation coefficient
        %use the consensus community structure
        [ParPos, ParNeg] = participation_coef_sign(A, Commun_affil);

        %% assortativity
        Ast_pos = assortativity_wei(A,0);
        %note: assorativity default 0 only looks at pos

        %for negative distribution
        neg_mat = -A;
        Ast_neg = assortativity_wei(neg_mat,0);

        %for absolute
        abs_mat = abs(A);
        Ast_abs = assortativity_wei(abs_mat,0);
        
        %% decide & implement thresholding
        minthresh = 0.15;
        maxthresh = 0.35;
        step = 0.01;   

        %% initialise data store
        glob_metrics = {'GEi'};
        threshlist = minthresh:step:maxthresh;
        globraw = nan(length(threshlist),length(glob_metrics));

        %% iterate across thresholds
        % in steps of 1
        i = 0;
        for thresh = minthresh:0.01:maxthresh
            i = i+1;%get the number of iterations
            W = threshold_proportional(A,thresh);%W is the thresholded matrix

            %% global efficiency
            globraw(i,1) = efficiency_wei(W,0);%global, not local, so 0

        end
        %% calculate AUC as outcome
        AUC = trapz(threshlist,globraw,1);%integrate over column for AUC
        
        %% degree and eigenvector centrality
        DegreeRaw = nan(length(threshlist),length(A));%num of column = num of nodes
        EigenRaw = nan(length(threshlist),length(A));
        StrengthRaw = nan(length(threshlist),length(A));
        i = 0;
        for thresh = minthresh:0.01:maxthresh
            i = i+1;%get the number of iterations
            W = threshold_proportional(A,thresh);%W is the thresholded matrix

            DegreeRaw(i,:) = degrees_und(W);
            StrengthRaw(i,:) = strengths_und_sign(W);
            EigenRaw(i,:) = eigenvector_centrality_und(W);
            
        end 
        Degree = trapz(threshlist,DegreeRaw,1)';%integrate over column; each column a region
        Eigen = trapz(threshlist,EigenRaw,1)';%need to make them column vectors
        Strength = trapz(threshlist,StrengthRaw,1)';
        
        %for the raw data
        raw_glob{subj} = globraw;
        raw_node{subj} = [DegreeRaw,EigenRaw,StrengthRaw];

        %% prepare for output
        Subject = str2num(snum{subj});
        subjectid = repmat(Subject,size(regnames));%repeat the subject name many times
        
        %first the main scalar measures
        metnames = [{'Subject','Modularity_Consensus','Modularity_Max','Assortativity','Assortativity_NegWeights','Assortativity_AbsWeights'},glob_metrics];

        %then the nodal statistics
        %disp([size(subjectid); size(regnames);size(Commun_affil);size(ParPos); size(ParNeg); size(Degree);size(Eigen)])
        nodmetnames = {'Subject','RegionNames','CommunityAffiliationVector','CommunityAffiliationVector_Max','ParCoef_Pos','ParCoef_Neg','Degree','EigenvectorCentrality','Strength'};
        
        %% combine output to previous
        if iteration == 1
            mets = table(Subject, Q_consensus, Q_max, Ast_pos,Ast_neg, Ast_abs, AUC,'Variablenames',metnames);
        else
            addt = table(Subject, Q_consensus, Q_max, Ast_pos,Ast_neg, Ast_abs, AUC,'Variablenames',metnames);
            mets = [mets;addt];
        end
        
        
        if iteration == 1
            nodal = table(subjectid, regnames, Commun_affil, CAV_max, ParPos, ParNeg, Degree, Eigen,Strength);
            nodal.Properties.VariableNames = nodmetnames;
        else
            addt_nod = table(subjectid, regnames, Commun_affil, CAV_max, ParPos, ParNeg, Degree, Eigen,Strength,'Variablenames',nodmetnames);
            nodal = [nodal;addt_nod];
        end
        
        %clear to prevent repeat
        clear fc
        clear Subject Q_consensus Ast_pos Ast_neg Ast_abs AUC
        clear subjectid regnames Commun_affil ParPos ParNeg Degree Eigen
        
        
        fprintf('completed subject %s \n',snum{subj})
    end

    %% output to csv
    writetable(mets,replace('LegacyGlobalGTA_XX.csv','XX',network))
    writetable(nodal,replace('LegacyNodalGTA_XX.csv','XX',network))    
    
    %store raw files
    save(replace('LegacyGlobalGTA_perThresh_XX.mat','XX',network),'raw_glob')
    save(replace('LegacyNodalGTA_perThresh_XX.mat','XX',network),'raw_node')
    
end

function y = myrename(x)
    %removes first few letters from cell array of strings
    y = cell(size(x));
    for i = 1:length(x)
        y{i}= x{i}(11:end);
        if ~strcmp(x{i}(1:9),'7Networks')
            disp('Warning: region name not from 7Networks_XXX')
        end
    end
end

function x = selflink(x)
    opd = diag(ones(length(x),1));
    opd = logical(opd);%create diagonal logical
    
    x(opd) = 0;
    
end

function Q = mymodularity(W, g,gamma)
    %based on the community_louvain code in brain connectivity toolbox
    %simply takes CAV (the g) and the A to compute the current modularity
    %note: uses negative asymmetric definition!

    W=double(W);                                % convert to double format
    n=length(W);                                % get number of nodes
    s=sum(sum(W));                              % get sum of edges
    
    %separate positive and negative
    W0 = W.*(W>0);                          %positive weights matrix
    s0 = sum(sum(W0));                      %weight of positive links
    B0 = W0-gamma*(sum(W0,2)*sum(W0,1))/s0; %positive modularity
    
    W1 =-W.*(W<0);                          %negative weights matrix
    s1 = sum(sum(W1));                      %weight of negative links
    if s1                                   %negative modularity
        B1 = W1-gamma*(sum(W1,2)*sum(W1,1))/s1;
    else
        B1 = 0;
    end
    
    %get everything before the Kronecker delta? summing comes next
    B = B0/s0 - B1/(s0+s1); 
    
    [~,~,Mb] = unique(g);

    B = (B+B.')/2;                                          % symmetrize modularity matrix
    Hnm=zeros(n,n);                                         % node-to-module degree
    for m=1:max(Mb)                                         % loop over modules
        Hnm(:,m)=sum(B(:,Mb==m),2);
    end

    Q = sum(B(bsxfun(@eq,g,g.')));                        % compute modularity
    

end